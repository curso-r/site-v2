---
title: "Monty hall e diagramas de influ√™ncia"
date: "2018-09-09T00:00:00+00:00"
categories: ["r", "conceitos"]
tags: ["r", "modelo", "historia"]
banner: "img/banners/montyhall.png"
author: ["Julio"]
summary: "O problema de Monty Hall √© talvez o mais eloquente exemplo de como a probabilidade pode confundir a mente humana. Esse problema desafiou a comunidade cient√≠fica no final do s√©culo XX e chegou at√© a ser considerado um paradoxo. Nesse post mostramos uma solu√ß√£o simples e elegante para o problema usando diagramas de influ√™ncia e o pacote bnlearn."
draft: false
---

Voc√™ est√° num jogo na TV e o apresentador pede para escolher uma entre 3 portas. Atr√°s de uma dessas portas tem uma **Ferrari** e nas outras duas temos **cabras**. Voc√™ escolhe uma porta. Depois, o apresentador retira uma porta que tem uma cabra e pergunta: **voc√™ quer trocar de porta?**

A princ√≠pio, voc√™ pode achar que sua probabilidade de ganhar √© 1/2, j√° que uma das portas foi retirada, ent√£o n√£o importa se voc√™ troca ou n√£o. Mas a resposta √© que sim, vale √† pena trocar de porta! A probabilidade de vencer o jogo trocando a porta √© de 2/3.

```{r echo=FALSE, fig.cap="Brincadeira do [XKCD](https://xkcd.com/1282/).", fig.align='center'}
knitr::include_graphics("https://imgs.xkcd.com/comics/monty_hall.png")
```


O problema de Monty Hall √© talvez o mais eloquente exemplo de como a probabilidade pode confundir a mente humana. Esse problema desafiou a comunidade cient√≠fica no final do s√©culo XX e chegou at√© a ser considerado um paradoxo. Recomendo ler o livro [O Andar do B√™bado](https://books.google.com.br/books/about/O_andar_do_b%C3%AAbado.html?id=X0niXrHmsZUC&redir_esc=y), de Leonard Mlodinow, que conta essa e muitas outras hist√≥rias interessantes sobre a probabilidade.

Existem v√°rias formas de explicar por qu√™ trocar a porta √© a melhor estrat√©gia. A que eu mais gosto √© a do pr√≥prio Andar do B√™bado, que mostra que, quando voc√™ escolhe a primeira porta, voc√™ est√° apostando se acertou ou n√£o a Ferrari. Se voc√™ apostar que acertou a Ferrari, n√£o deve trocar a porta e, se voc√™ apostar que errou a Ferrari, deve trocar. A aposta de errar a Ferrari de primeira tem probabilidade 2/3, logo, vale √† pena trocar.

Nesse post, mostramos uma solu√ß√£o alternativa, simples e elegante para o problema usando diagramas de influ√™ncia e o pacote `bnlearn`.


### Redes bayesianas

As redes Bayesianas s√£o o resultado da combina√ß√£o de conceitos probabil√≠sticos e conceitos da teoria dos grafos. Segundo Pearl, tal uni√£o tem como consequ√™ncias tr√™s benef√≠cios: i) prover formas convenientes para expressar suposi√ß√µes do modelo; ii) facilitar a representa√ß√£o de fun√ß√µes de probabilidade conjuntas; e iii) facilitar o c√°lculo eficiente de infer√™ncias a partir de observa√ß√µes.

Da teoria de probabilidades precisamos apenas de alguns resultados b√°sicos sobre probabilidade condicional. Primeiramente, pela defini√ß√£o de probabilidade condicional, sabemos que

$$
p(x_1, x_2) = p(x_1)p(x_2|x_1).
$$

Aplicando essa regra iterativamente para $n$ vari√°veis, temos

$$
p(x_1, \dots, x_p) = \prod_j p(x_j|x_1,\dots, x_{j-1}).
$$

Agora, imagine que, no seu problema, a vari√°vel aleat√≥ria $X_j$ n√£o dependa probabilisticamente de todas as vari√°veis $X_1,\dots, X_{j-1}$, e sim apenas de um subconjunto $\Pi_j$ dessas vari√°veis. Fazendo isso, a equa√ß√£o pode ser escrita como

$$
p(x_1, \dots, x_p) = \prod_j p(x_j|\pi_j).
$$

Chamamos $\Pi_j$ de **pais** de $X_j$. Esse conjunto pode ser pensado como as vari√°veis que s√£o suficientes para determinar as probabilidades de $X_j$.

A parte mais legal das redes Bayesianas √© que elas podem ser representadas a partir de DAGs (grafos direcionados ac√≠clicos). No grafo, se $X_1$ aponta para $X_2$, ent√£o $X_1$ √© pai de $X_2$. Por exemplo, esse grafo aqui

<center>

```{r exemplo, echo=FALSE, out.width="100%"}
DiagrammeR::DiagrammeR(stringr::str_replace_all("
graph LR;
A(X1Esta√ß√£o do ano)-->B(X2Regador ligado)
A-->C(X3Choveu)
B-->D(X4Ch√£o Molhado)
C-->D
D-->E(X5Ch√£o Escorregadio)
", "X([0-9])", "<center><b>X\\1</b></center><br/>"))
```

</center>

representa a distribui√ß√£o de probabilidades $p(x_1, \dots, x_5)$ com

$$
p(x_1, \dots, x_5) = p(x_1)p(x_2|x_1)p(x_3|x_1)p(x_4|x_3,x_2)p(x_5|x_4).
$$


### Diagrama de influ√™ncias

Um diagrama e influ√™ncias √© uma rede Bayesiana com n√≥s de decis√£o e utilidade (ganhos). Ou seja, √© uma jun√ß√£o de tr√™s conceitos: 

$$
\underbrace{\text{prob. condicional} + \text{grafos}}_{\text{rede Bayesiana}} + \text{teoria da decis√£o} = \text{diagrama de influ√™ncias}
$$

Na teoria da decis√£o, usualmente estamos interessados em maximizar a utilidade esperada. No diagrama, considerando a estrutura de probabilidades dada pela rede Bayesiana e as informa√ß√µes dispon√≠veis, queremos escolher a decis√£o que faz com que, em m√©dia, nosso retorno seja mais alto.

Com diagramas de influ√™ncias, √© poss√≠vel organizar sistemas complexos com m√∫ltiplas decis√µes, considerando diferentes conjuntos de informa√ß√µes dispon√≠veis. √â uma ferramenta realmente muito poderosa.

## Voltando ao Monty Hall

Agora que sabemos um pouquinho de diagramas de influ√™ncia, podemos desenhar o do Monty Hall:

<center>

```{r diagrama, echo=FALSE, out.width="100%"}
DiagrammeR::DiagrammeR(stringr::str_replace_all("
graph LR;
A{D1Escolha inicial}-->B(X2Porta retirada);
C(X1Ferrari)-->B;
B-->D{D2Trocar porta};
D-->E[U1Ganhar]
C-->E
A-->E
", "([XDU][0-9])", "<center><b>\\1</b></center><br/>"))
```

</center>

O jogador tem duas decis√µes a tomar:

- $D_1$ (`escolha_inicial`): A escolha da porta inicial (`1`, `2`, `3`).
- $D_2$ (`trocar`): Trocar a porta ou n√£o (`s`, `n`).

Tamb√©m temos duas fontes de incerteza:

- $X_1$ (`ferrari`): Em qual porta est√° a Ferrari (`1`, `2`, `3`).
- $X_2$ (`porta_retirada`): Qual porta foi retirada (`1`, `2`, `3`). Essa vari√°vel n√£o √© sempre aleat√≥ria: se eu escolho a porta 1 e a Ferrari est√° em 2, o apresentador √© obrigado a retirar a porta 3. Se o apresentador tiver a op√ß√£o de escolher (que acontece no caso da escolha inicial ser a Ferrari), o apresentador escolhe uma porta para retirar aleatoriamente.

Finalmente, temos um n√≥ de utilidade:

- $U_1$ (`result`): Ganhei a Ferrari (`ganhei`, `perdi`).

Em R, podemos construir a rede Bayesiana do problema utilizando o pacote `bnlearn`:

```{r grafo, eval=TRUE}
# n√≥s do grafo
nodes <- c("escolha_inicial", "ferrari", "porta_retirada", "trocar", "result")

# matriz de adjac√™ncias
edges <- matrix(
  c("escolha_inicial", "porta_retirada",
    "ferrari", "porta_retirada",
    "porta_retirada", "trocar",
    "trocar", "result",
    "ferrari", "result",
    "escolha_inicial", "result"),
  ncol = 2, 
  byrow = TRUE)

edges

# criando o grafo a partir de um grafo vazio
g <- bnlearn::empty.graph(nodes)
bnlearn::arcs(g) <- edges
```

O output desse conjunto de opera√ß√µes √© um objeto do tipo `bn` com v√°rias propriedades pr√© calculadas pelo pacote `bnlearn`:

```{r bn, eval=FALSE}
g
```

```
  Random/Generated Bayesian network

  model:
   [escolha_inicial][ferrari][porta_retirada|escolha_inicial:ferrari][trocar|porta_retirada]
   [result|escolha_inicial:ferrari:trocar]
  nodes:                                 5 
  arcs:                                  6 
    undirected arcs:                     0 
    directed arcs:                       6 
  average markov blanket size:           3.60 
  average neighbourhood size:            2.40 
  average branching factor:              1.20 

  generation algorithm:                  Empty 
```

Com as especifica√ß√£o do problema dada, se gerarmos aleatoriamente todos os cen√°rios, chegamos √† essa combina√ß√£o de casos equiprov√°veis (ver Extra 2)

Agora, vamos escrever todas as combina√ß√µes poss√≠veis de cen√°rios e guardar num `data.frame` chamado `dados`:

```{r dados, echo=FALSE}
library(magrittr)
dados <- tibble::tribble(
  ~escolha_inicial, ~ferrari, ~porta_retirada, ~trocar, ~result,
  # escolha inicial 1 -------------------------------------------
  "1"             , "1"     , "2"            , "n"    , "ganhei",
  "1"             , "1"     , "2"            , "s"    , "perdi" ,
  "1"             , "1"     , "3"            , "n"    , "ganhei",
  "1"             , "1"     , "3"            , "s"    , "perdi" ,
  "1"             , "2"     , "3"            , "n"    , "perdi" , 
  "1"             , "2"     , "3"            , "s"    , "ganhei", 
  "1"             , "3"     , "2"            , "n"    , "perdi" ,
  "1"             , "3"     , "2"            , "s"    , "ganhei",
  # escolha inicial 2 -------------------------------------------
  "2"             , "1"     , "3"            , "n"    , "perdi" ,
  "2"             , "1"     , "3"            , "s"    , "ganhei",
  "2"             , "2"     , "1"            , "n"    , "ganhei",
  "2"             , "2"     , "1"            , "s"    , "perdi" ,
  "2"             , "2"     , "3"            , "n"    , "ganhei",
  "2"             , "2"     , "3"            , "s"    , "perdi" ,
  "2"             , "3"     , "1"            , "n"    , "perdi" ,
  "2"             , "3"     , "1"            , "s"    , "ganhei",
  # escolha inicial 3 -------------------------------------------
  "3"             , "1"     , "2"            , "n"    , "perdi" ,
  "3"             , "1"     , "2"            , "s"    , "ganhei",
  "3"             , "2"     , "1"            , "n"    , "perdi" ,
  "3"             , "2"     , "1"            , "s"    , "ganhei",
  "3"             , "3"     , "2"            , "n"    , "ganhei",
  "3"             , "3"     , "2"            , "s"    , "perdi" ,
  "3"             , "3"     , "1"            , "n"    , "ganhei",
  "3"             , "3"     , "1"            , "s"    , "perdi" 
) %>% 
  dplyr::mutate_all(as.factor) %>% 
  data.frame(stringsAsFactors = TRUE)

knitr::kable(dados)
```

Finalmente, ajustamos nossa rede Bayesiana, usando a fun√ß√£o `bnlearn::bn.fit()`.

```{r modelo, eval=FALSE}
fit <- bnlearn::bn.fit(g, dados)
```

A fun√ß√£o `bnlearn::cpquery()` (conditional probability query) serve para realizar uma consulta de probabilidades dada a rede ajustada. No nosso caso, a partir de uma escolha inicial qualquer $d_1$, queremos saber o ganho ao trocar √© maior que o ganho ao n√£o trocar.

$$
\mathbb E(U_1\; |\; D_2 = \text{s}, D_1 = d_1) > \mathbb E(U_1\; |\; D_2 = \text{n}, D_1 = d_1).
$$

Fazendo contas, isso equivale matematicamente a consultar se

$$
\mathbb P(U_1=\text{ganhei}\; |\; D_2 = \text{s}) > \mathbb P(U_1=\text{ganhei}\; |\; D_2 = \text{n})
$$

Agora, podemos consultar $\mathbb P(U_1=\text{ganhei}\; |\; D_2 = \text{s})$ com nosso modelo!

```{r query1, eval=FALSE}
set.seed(13)                    # reprodutibilidade
bnlearn::cpquery(
  fitted = fit, 
  event = (result == "ganhei"), # o que queremos saber?
  evidence = (trocar == "s"),   # qual informa√ß√£o adicionar?
  n = 5e6)                      # n grande para aumentar a precis√£o
```

```
[1] 0.6666704
```

E n√£o √© que d√° 2/3 mesmo? Da mesma forma, temos

```{r query2, eval=FALSE}
bnlearn::cpquery(fit, (result == "ganhei"), (trocar == "n"), n = 5e6)
```

```
[1] 0.3333187
```

Resolvido!

## Wrap-up

- Vale √† pena trocar a porta!
- Redes Bayesianas juntam grafos e probabilidades condicionais
- Diagramas de influ√™ncia juntam redes Bayesianas e teoria da decis√£o
- Essas ferramentas podem ser utilizadas tanto para resolver Monty Hall quanto para ajudar em sistemas complexos.

√â isso pessoal. Happy coding ;)

### Extra

Se voc√™ ficou interessada em como eu fiz o diagrama, utilizei o pacote `DiagrammeR`. O c√≥digo est√° aqui:

```{r diagrama-code, eval=FALSE}
diagrama <- "
graph LR;
A{D1Escolha inicial}-->B(X2Porta retirada);
C(X1Ferrari)-->B;
B-->D{D2Trocar porta};
D-->E[U1Ganhar]
C-->E
A-->E
"
# tweak para centralizar e grifar as vari√°veis
diagrama <- stringr::str_replace_all(
  diagrama, 
  pattern = "([XDU][0-9])", 
  replacement = "<center><b>\\1</b></center><br/>")

DiagrammeR::DiagrammeR(diagrama)
```

### Extra 2

√â poss√≠vel simular os dados que coloquei no post com uma fun√ß√£o simples, que adicionei abaixo. Na verdade, o fato de eu ter considerado somente as combina√ß√µes √∫nicas de cen√°rios e n√£o os dados simulados abaixo √© um pouco roubado, e s√≥ funciona porque os cen√°rios calham de ser, de fato, equiprov√°veis.

```{r eval=FALSE}
set.seed(13)

simular_monty_hall <- function(z = 0) {
  v <- 1:3                                  # opcoes
  escolha_inicial <- sample(v, 1)           # escolha inicial aleatoria
  ferrari <- sample(v, 1)                   # ferrari aleatoria
  
  # qual porta retirar?
  if (escolha_inicial == ferrari) {
    porta_retirada <- sample(setdiff(v, ferrari), 1)
  } else {
    porta_retirada <- setdiff(v, c(escolha_inicial, ferrari))
  }
  
  # trocar porta?
  trocar <- sample(c("s", "n"), 1)
  
  # calculando resultado
  if (trocar == "s") {
    escolha_final <- setdiff(v, c(escolha_inicial, porta_retirada))
  } else {
    escolha_final <- escolha_inicial
  }
  result <- ifelse(escolha_final == ferrari, "ganhei", "perdi")
  
  # guardando no BD
  tibble::tibble(escolha_inicial, ferrari, porta_retirada, trocar, result)
}

dados_simulados <- purrr::map_dfr(seq_len(1e4), simular_monty_hall) %>% 
  dplyr::mutate_all(as.factor)

dplyr::glimpse(dados_simulados)
```

```
Observations: 10,000
Variables: 5
$ escolha_inicial <fct> 3, 1, 2, 1, 1, 1, 3, 1, 2, 3, 3, 1, 3, 1, 2, 2, 2,...
$ ferrari         <fct> 1, 1, 2, 1, 1, 2, 3, 3, 1, 2, 3, 3, 2, 1, 1, 3, 1,...
$ porta_retirada  <fct> 2, 3, 1, 3, 2, 3, 2, 2, 3, 1, 1, 2, 1, 2, 3, 1, 3,...
$ trocar          <fct> n, s, s, n, s, n, n, n, n, s, s, s, s, n, n, s, n,...
$ result          <fct> perdi, perdi, perdi, ganhei, perdi, perdi, ganhei,...
```

Os dados do post podem ser obtidos fazendo isso aqui:

```{r eval=FALSE}
dados_simulados %>% 
  dplyr::distinct() %>% 
  dplyr::arrange(escolha_inicial, ferrari)
```

Agradecimentos: [Rafael Stern](https://www.rafaelstern.science/), que me convenceu de que vale √† pena mostrar os dados simulados üòâ
